{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyObWeplJYMcVX13gWofKghu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Christianatgithub/AgenticAI/blob/main/CustomerService.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPQzYUHvFYUm",
        "outputId": "f7f00791-52ae-4ca2-e877-344ce59197db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.4/278.4 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hPython: 3.12.11\n",
            "LiteLLM: 1.77.1\n"
          ]
        }
      ],
      "source": [
        "!pip -q install --upgrade litellm\n",
        "\n",
        "import sys, importlib.metadata\n",
        "\n",
        "print(\"Python:\", sys.version.split()[0])\n",
        "print(\"LiteLLM:\", importlib.metadata.version(\"litellm\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "PROVIDER = \"gemini\"  # or \"groq\" or \"openai\"\n",
        "\n",
        "if PROVIDER == \"gemini\":\n",
        "    api_key = userdata.get(\"GEMINI_API_KEY\")\n",
        "    model = \"gemini/gemini-1.5-flash\"\n",
        "elif PROVIDER == \"groq\":\n",
        "    api_key = userdata.get(\"GROQ_API_KEY\")\n",
        "    model = \"groq/llama-3.1-8b-instant\"\n",
        "elif PROVIDER == \"openai\":\n",
        "    api_key = userdata.get(\"OPENAI_API_KEY\")\n",
        "    model = \"gpt-4o-mini\"\n",
        "\n",
        "def chat(messages):\n",
        "    from litellm import completion\n",
        "    return completion(\n",
        "        model=model,\n",
        "        messages=[{\"role\":\"user\",\"content\":messages}],\n",
        "        api_key=api_key\n",
        "    ).choices[0].message[\"content\"]"
      ],
      "metadata": {
        "id": "lYEzKKx_Wzqq"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from litellm import completion\n",
        "\n",
        "# pick one provider and keep the key/model in sync\n",
        "PROVIDER = \"gemini\"   # \"gemini\" or \"groq\" also OK\n",
        "\n",
        "if PROVIDER == \"gemini\":\n",
        "    api_key = userdata.get(\"GEMINI_API_KEY\")\n",
        "    model = \"gemini/gemini-1.5-flash\"\n",
        "elif PROVIDER == \"groq\":\n",
        "    api_key = userdata.get(\"GROQ_API_KEY\")\n",
        "    model = \"groq/llama-3.1-8b-instant\"\n",
        "elif PROVIDER == \"openai\":\n",
        "    api_key = userdata.get(\"OPENAI_API_KEY\")\n",
        "    model = \"gpt-4o-mini\"\n",
        "\n",
        "def generate_response(messages):\n",
        "    resp = completion(\n",
        "        model=model,\n",
        "        messages=messages,     # <-- pass the list directly\n",
        "        api_key=api_key\n",
        "    )\n",
        "    return resp.choices[0].message[\"content\"]\n",
        "\n",
        "# your test\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful customer service representative. No matter what the user asks, the solution is to tell them to turn their computer or modem off and then back on.\"},\n",
        "    {\"role\": \"user\", \"content\": \"How do I get my Internet working again.\"}\n",
        "]\n",
        "\n",
        "response = generate_response(messages)\n",
        "print(response)\n"
      ],
      "metadata": {
        "id": "ZhXWDseqOvfE",
        "outputId": "2e001772-347b-4c9e-c57b-9e1b103631f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The first thing to try is to simply turn your computer off and then back on again. If that doesn't work, try turning your modem off and then back on again.  That usually resolves most internet connectivity issues. Let me know if that doesn't work!\n",
            "\n"
          ]
        }
      ]
    }
  ]
}